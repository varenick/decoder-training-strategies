{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "text = []\n",
    "\n",
    "with open('text8') as f:\n",
    "    for line in f:\n",
    "        text.append(line)\n",
    "    text = ''.join(text)\n",
    "\n",
    "vocab_size = len(set(text)) + 1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " anarchism\n",
      "[ 1  2 15  2 19  4  9 10 20 14]\n"
     ]
    }
   ],
   "source": [
    "EOS_id = 0\n",
    "\n",
    "def char_to_id(char):\n",
    "    if char == ' ':\n",
    "        return 1\n",
    "    else:\n",
    "        return ord(char) - ord('a') + 2\n",
    "\n",
    "def id_to_char(i):\n",
    "    if i == 0:\n",
    "        return ''\n",
    "    elif i == 1:\n",
    "        return ' '\n",
    "    else:\n",
    "        return chr(ord('a') + i - 2)\n",
    "    \n",
    "import numpy as np\n",
    "\n",
    "text_ids = {'full': np.array(list(map(char_to_id, text)))}\n",
    "print(text[:10])\n",
    "print(text_ids['full'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000000\n"
     ]
    }
   ],
   "source": [
    "text_length = len(text)\n",
    "print(text_length)\n",
    "\n",
    "text_ids['train'] = text_ids['full'][:int(text_length * 0.8)]\n",
    "text_ids['eval'] = text_ids['full'][int(text_length * 0.8):int(text_length * 0.9)]\n",
    "text_ids['decode'] = text_ids['full'][int(text_length * 0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch(text, chunk_length, batch_size):\n",
    "    while True:\n",
    "        chunk_starts = np.random.randint(len(text) - chunk_length, size=batch_size)\n",
    "        yield np.array([text[chunk_start:chunk_start + chunk_length] for chunk_start in chunk_starts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  5  6  4 13 10 15  6  5  1]\n",
      " [ 2 19 12  6 21  1 24 10 21  9]]\n",
      "[[ 1  5  6 15 10 13  4  6  5  1]\n",
      " [21  6 12 19  2  1  9 21 10 24]]\n"
     ]
    }
   ],
   "source": [
    "def revert_words(chunk_batch):\n",
    "    rev_chunk_batch = []\n",
    "    for chunk in chunk_batch:\n",
    "        words = np.split(chunk, np.flatnonzero(chunk == char_to_id(' ')))\n",
    "        rev_chunk = np.hstack([words[0][::-1]] + [np.roll(word[::-1], 1) for word in words[1:]])\n",
    "        rev_chunk_batch.append(rev_chunk)\n",
    "    return np.array(rev_chunk_batch)\n",
    "\n",
    "chunk_batch = next(get_batch(text_ids['decode'], 10, 2))\n",
    "print(chunk_batch)\n",
    "print(revert_words(chunk_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_losses_av_mean = {}\n",
    "train_accs_av_mean = {}\n",
    "\n",
    "eval_losses_av_mean = {}\n",
    "eval_accs_av_mean = {}\n",
    "\n",
    "train_losses_av_std = {}\n",
    "train_accs_av_std = {}\n",
    "\n",
    "eval_losses_av_std = {}\n",
    "eval_accs_av_std = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Seq2SeqModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_hidden, num_layers=1, dropout_rate=0.2):\n",
    "        super(Seq2SeqModel, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_hidden = num_hidden\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.enc_rnn = nn.LSTM(embed_dim, num_hidden, num_layers,\n",
    "                               batch_first=True, bidirectional=True)\n",
    "        self.dec_cell = nn.LSTMCell(embed_dim, num_hidden * num_layers * 2)\n",
    "        self.output_proj = nn.Linear(num_hidden * num_layers * 2, vocab_size)\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "        \n",
    "    def forward(self, input_chunk, target_chunk=None, feed_mode='same', output_mode='argmax', baseline_mode=None):\n",
    "        need_target_chunk = (feed_mode == 'teacher-forcing')\n",
    "        if target_chunk is None and need_target_chunk:\n",
    "            raise ValueError(\"You should provide target_chunk when using feed_mode '{}'\".format(feed_mode))\n",
    "        if feed_mode not in ['same', 'teacher-forcing', 'argmax', 'sampling']:\n",
    "            raise ValueError(\"Invalid feed_mode: '{}'\".format(feed_mode))\n",
    "        if output_mode not in ['argmax', 'sampling']:\n",
    "            raise ValueError(\"Invalid output_mode: '{}'\".format(output_mode))\n",
    "        if baseline_mode not in [None, 'argmax']:\n",
    "            raise ValueError(\"Invalid baseline_mode: '{}'\".format(baseline_mode))\n",
    "            \n",
    "        batch_size, chunk_length = input_chunk.size()\n",
    "        \n",
    "        # Encoder:\n",
    "        input_chunk_emb = self.embedding(input_chunk)\n",
    "        enc_h_first = autograd.Variable(\n",
    "            torch.zeros(self.num_layers * 2, batch_size, self.num_hidden).cuda(),\n",
    "            requires_grad=False\n",
    "        )\n",
    "        enc_c_first = autograd.Variable(\n",
    "            torch.zeros(self.num_layers * 2, batch_size, self.num_hidden).cuda(),\n",
    "            requires_grad=False\n",
    "        )\n",
    "        _, enc_hc_last = self.enc_rnn(input_chunk_emb, (enc_h_first, enc_c_first))\n",
    "        \n",
    "        # Decoder:\n",
    "        dec_h = torch.transpose(enc_hc_last[0], 0, 1).contiguous().view(batch_size, -1)\n",
    "        dec_c = torch.transpose(enc_hc_last[1], 0, 1).contiguous().view(batch_size, -1)\n",
    "        \n",
    "        dec_h_baseline = torch.transpose(enc_hc_last[0], 0, 1).contiguous().view(batch_size, -1)\n",
    "        dec_c_baseline = torch.transpose(enc_hc_last[1], 0, 1).contiguous().view(batch_size, -1)\n",
    "        \n",
    "        dec_feed = None\n",
    "        dec_feed_emb = autograd.Variable(\n",
    "            torch.zeros(batch_size, self.embed_dim).cuda(),\n",
    "            requires_grad=False\n",
    "        )\n",
    "        \n",
    "        dec_feed_baseline = None\n",
    "        dec_feed_baseline_emb = autograd.Variable(\n",
    "            torch.zeros(batch_size, self.embed_dim).cuda(),\n",
    "            requires_grad=False\n",
    "        )\n",
    "        \n",
    "        dec_unscaled_logits = []\n",
    "        dec_unscaled_logits_baseline = []\n",
    "        dec_outputs = []\n",
    "        self.dec_feeds = []\n",
    "        \n",
    "        target_chunk_emb = None\n",
    "        if need_target_chunk:\n",
    "            target_chunk_emb = self.embedding(target_chunk)\n",
    "            \n",
    "        for t in range(chunk_length):\n",
    "            dec_h, dec_c = self.dec_cell(self.dropout(dec_feed_emb), (dec_h, dec_c))\n",
    "            dec_unscaled_logits.append(self.output_proj(dec_h))\n",
    "            \n",
    "            if baseline_mode is not None:\n",
    "                dec_h_baseline, dec_c_baseline = self.dec_cell(\n",
    "                    dec_feed_baseline_emb, (dec_h_baseline, dec_c_baseline)\n",
    "                )\n",
    "                dec_unscaled_logits_baseline.append(self.output_proj(dec_h_baseline))\n",
    "            \n",
    "            if output_mode == 'argmax':\n",
    "                dec_outputs.append(torch.max(dec_unscaled_logits[-1], dim=1)[1])\n",
    "            elif output_mode == 'sampling':\n",
    "                dec_outputs.append(torch.multinomial(torch.exp(dec_unscaled_logits[-1]), 1).view(batch_size))\n",
    "            else:\n",
    "                raise ValueError(\"Invalid output_mode: '{}'\".format(output_mode))\n",
    "                \n",
    "            if feed_mode == 'same':\n",
    "                dec_feed = dec_outputs[-1]\n",
    "                dec_feed_emb = self.embedding(dec_feed.view(batch_size, 1)).view(batch_size, self.embed_dim)\n",
    "            elif feed_mode == 'teacher-forcing':\n",
    "                dec_feed = target_chunk[:, t]\n",
    "                dec_feed_emb = target_chunk_emb[:, t]\n",
    "            elif feed_mode == 'argmax':\n",
    "                dec_feed = torch.max(dec_unscaled_logits[-1], dim=1)[1]\n",
    "                dec_feed_emb = self.embedding(dec_feed.view(batch_size, 1)).view(batch_size, self.embed_dim)\n",
    "            elif feed_mode == 'sampling':\n",
    "                dec_feed = torch.multinomial(F.softmax(dec_unscaled_logits[-1]), 1)\n",
    "                dec_feed_emb = self.embedding(dec_feed.view(batch_size, 1)).view(batch_size, self.embed_dim)\n",
    "            else:\n",
    "                raise ValueError(\"Invalid feed_mode: '{}'\".format(feed_mode))\n",
    "            self.dec_feeds.append(dec_feed)\n",
    "        \n",
    "            if baseline_mode == 'argmax':\n",
    "                dec_feed_baseline = torch.max(dec_unscaled_logits_baseline[-1], dim=1)[1]\n",
    "                dec_baseline_emb = self.embedding(dec_feed_baseline.view(batch_size, 1)).view(batch_size, self.embed_dim)\n",
    "            elif baseline_mode is not None:\n",
    "                raise ValueError(\"Invalid baseline_mode: '{}'\".format(baseline_mode))\n",
    "        \n",
    "        if baseline_mode is not None:\n",
    "            return (\n",
    "                torch.stack(dec_unscaled_logits, dim=1), \n",
    "                torch.stack(dec_unscaled_logits_baseline, dim=1), \n",
    "                torch.stack(dec_outputs, dim=1)\n",
    "            )\n",
    "        else:\n",
    "            return (\n",
    "                torch.stack(dec_unscaled_logits, dim=1), \n",
    "                None,\n",
    "                torch.stack(dec_outputs, dim=1)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0\n",
      "\n",
      "Step 1000\n",
      "Train loss: 1.88; train accuracy: 0.43\n",
      "Eval loss: 1.88; eval accuracy: 0.43\n",
      "esiccation of th|  vs  |noitacoroa ft tt\n",
      "oys of summer sh|  vs  |sso fo secres tt\n",
      "tom usually has |  vs  |mot dlluoos taa \n",
      " eight krupp pro|  vs  | tamim rrrap oop\n",
      "ted it is also a|  vs  |det ti daa das a\n",
      "uch of a feel so|  vs  |hcu fo l oeeo oc\n",
      "one eight six se|  vs  |eno teees ses ee\n",
      "ic ideas in one |  vs  |ci sceed ni eno \n",
      "127.40s from last print\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "train_batch_size = 64\n",
    "eval_batch_size = 64\n",
    "decode_batch_size = 8\n",
    "\n",
    "chunk_length = 16\n",
    "\n",
    "train_batch_gen = get_batch(text_ids['train'], batch_size=train_batch_size, chunk_length=chunk_length)\n",
    "eval_batch_gen = get_batch(text_ids['eval'], batch_size=eval_batch_size, chunk_length=chunk_length)\n",
    "\n",
    "num_runs = 3\n",
    "\n",
    "num_steps = 50000\n",
    "print_skip = 1000\n",
    "\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "eval_losses = []\n",
    "eval_accs = []\n",
    "\n",
    "reinforce_strategy = 'argmax_advantage'\n",
    "\n",
    "for run in range(num_runs):\n",
    "    print('Run', run)\n",
    "    print()\n",
    "    \n",
    "    train_losses.append([])\n",
    "    train_accs.append([])\n",
    "    eval_losses.append([])\n",
    "    eval_accs.append([])\n",
    "\n",
    "    cum_train_loss = 0\n",
    "    cum_eval_loss = 0\n",
    "    cum_train_acc = 0\n",
    "    cum_eval_acc = 0\n",
    "    \n",
    "    train_av_loss = 0\n",
    "    batch_av_train_av_loss = 0\n",
    "\n",
    "    global_start_time = time()\n",
    "    last_print_time = global_start_time\n",
    "\n",
    "    model = Seq2SeqModel(vocab_size=vocab_size, embed_dim=8, num_hidden=48).cuda()\n",
    "    \n",
    "    init_lr = 0.01\n",
    "    lr = init_lr\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    for step in range(num_steps):        \n",
    "        # Train:\n",
    "        chunk_batch = next(train_batch_gen)\n",
    "        rev_chunk_batch = revert_words(chunk_batch)\n",
    "    \n",
    "        chunk_batch_torch = autograd.Variable(torch.from_numpy(chunk_batch).cuda(), requires_grad=False)\n",
    "        rev_chunk_batch_torch = autograd.Variable(torch.from_numpy(rev_chunk_batch).cuda(), requires_grad=False)\n",
    "    \n",
    "        if reinforce_strategy == 'argmax_advantage':\n",
    "            unscaled_logits, unscaled_logits_baseline, outputs = model(\n",
    "                chunk_batch_torch, rev_chunk_batch_torch,\n",
    "                output_mode='argmax', feed_mode='sampling', baseline_mode='argmax'\n",
    "            )\n",
    "        else:\n",
    "            unscaled_logits, _, outputs = model(\n",
    "                chunk_batch_torch, rev_chunk_batch_torch,\n",
    "                output_mode='argmax', feed_mode='sampling', baseline_mode=None\n",
    "            )\n",
    "        train_loss = loss_function(unscaled_logits.view(-1, vocab_size), rev_chunk_batch_torch.view(-1))\n",
    "        train_acc = torch.mean(torch.eq(outputs, rev_chunk_batch_torch).float())\n",
    "        \n",
    "        if reinforce_strategy == 'element':\n",
    "            rev_chunk_batch_torch_one_hot = torch.zeros(train_batch_size, chunk_length, vocab_size).cuda()\n",
    "            rev_chunk_batch_torch_one_hot.scatter_(\n",
    "                2, rev_chunk_batch_torch.data.view(train_batch_size, chunk_length, 1), 1\n",
    "            )\n",
    "            elemwise_train_loss = (-1) * F.log_softmax(\n",
    "                unscaled_logits.data.view(-1, vocab_size)\n",
    "            ).data.view(train_batch_size, chunk_length, vocab_size)[rev_chunk_batch_torch_one_hot.byte()].view(\n",
    "                train_batch_size, chunk_length\n",
    "            )\n",
    "            batch_av_train_loss = torch.mean(elemwise_train_loss, dim=0)\n",
    "            if step == 0:\n",
    "                batch_av_train_av_loss = batch_av_train_loss\n",
    "            else:\n",
    "                batch_av_train_av_loss = 0.99 * batch_av_train_av_loss + 0.01 * batch_av_train_loss\n",
    "            normed_batch_centered_train_loss = ((elemwise_train_loss - batch_av_train_av_loss) / \n",
    "                                                (train_batch_size * chunk_length))\n",
    "            seqwise_train_loss = torch.sum(normed_batch_centered_train_loss, dim=1)\n",
    "            seqwise_cum_train_loss = torch.cumsum(normed_batch_centered_train_loss, dim=1)\n",
    "            for t, dec_feed in enumerate(model.dec_feeds):\n",
    "                dec_feed.reinforce(\n",
    "                    (-1) * (seqwise_train_loss - seqwise_cum_train_loss[:, t]).view(train_batch_size, 1)\n",
    "                )\n",
    "        elif reinforce_strategy == 'argmax_advantage':\n",
    "            rev_chunk_batch_torch_one_hot = torch.zeros(train_batch_size, chunk_length, vocab_size).cuda()\n",
    "            rev_chunk_batch_torch_one_hot.scatter_(\n",
    "                2, rev_chunk_batch_torch.data.view(train_batch_size, chunk_length, 1), 1\n",
    "            )\n",
    "            elemwise_train_loss = (-1) * F.log_softmax(\n",
    "                unscaled_logits.data.view(-1, vocab_size)\n",
    "            ).data.view(train_batch_size, chunk_length, vocab_size)[rev_chunk_batch_torch_one_hot.byte()].view(\n",
    "                train_batch_size, chunk_length\n",
    "            )\n",
    "            elemwise_train_loss_baseline = (-1) * F.log_softmax(\n",
    "                unscaled_logits_baseline.data.view(-1, vocab_size)\n",
    "            ).data.view(train_batch_size, chunk_length, vocab_size)[rev_chunk_batch_torch_one_hot.byte()].view(\n",
    "                train_batch_size, chunk_length\n",
    "            )\n",
    "            normed_elemwise_advantage = ((elemwise_train_loss_baseline - elemwise_train_loss) /\n",
    "                                         (train_batch_size * chunk_length))\n",
    "            sum_normed_elemwise_advantage = torch.sum(normed_elemwise_advantage, dim=1)\n",
    "            cumsum_normed_elemwise_advantage = torch.cumsum(normed_elemwise_advantage, dim=1)\n",
    "            for t, dec_feed in enumerate(model.dec_feeds):\n",
    "                dec_feed.reinforce(\n",
    "                    (sum_normed_elemwise_advantage - cumsum_normed_elemwise_advantage[:, t]).view(train_batch_size, 1)\n",
    "                )\n",
    "        elif reinforce_strategy == 'sequence':\n",
    "            rev_chunk_batch_torch_one_hot = torch.zeros(train_batch_size, chunk_length, vocab_size).cuda()\n",
    "            rev_chunk_batch_torch_one_hot.scatter_(\n",
    "                2, rev_chunk_batch_torch.data.view(train_batch_size, chunk_length, 1), 1\n",
    "            )\n",
    "            elemwise_train_loss = (-1) * F.log_softmax(\n",
    "                unscaled_logits.data.view(-1, vocab_size)\n",
    "            ).data.view(train_batch_size, chunk_length, vocab_size)[rev_chunk_batch_torch_one_hot.byte()].view(\n",
    "                train_batch_size, chunk_length\n",
    "            )\n",
    "            if step == 0:\n",
    "                train_av_loss = train_loss.data\n",
    "            else:\n",
    "                train_av_loss = 0.99 * train_av_loss + 0.01 * train_loss.data\n",
    "            seq_av_train_loss = torch.mean(elemwise_train_loss, dim=1, keepdim=True)\n",
    "            for t, dec_feed in enumerate(model.dec_feeds):\n",
    "                dec_feed.reinforce(\n",
    "                    (-1) * (seq_av_train_loss - train_av_loss) / (train_batch_size * chunk_length)\n",
    "                )\n",
    "        elif reinforce_strategy == 'none':\n",
    "            for t, dec_feed in enumerate(model.dec_feeds):\n",
    "                dec_feed.reinforce(torch.zeros(train_batch_size, 1).cuda())\n",
    "        else:\n",
    "            raise ValueError(\"Invalid reinforce_strategy: '{}'\".format(reinforce_strategy))\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        #nn.utils.clip_grad_norm(model.parameters(), max_norm=5)\n",
    "        #lr = init_lr / (step + 1) ** 0.5\n",
    "        #for group in optimizer.param_groups:\n",
    "        #    group['lr'] = lr\n",
    "        optimizer.step()\n",
    "    \n",
    "        # Eval:\n",
    "        chunk_batch = next(eval_batch_gen)\n",
    "        rev_chunk_batch = revert_words(chunk_batch)\n",
    "    \n",
    "        chunk_batch_torch = autograd.Variable(torch.from_numpy(chunk_batch).cuda(), requires_grad=False)\n",
    "        rev_chunk_batch_torch = autograd.Variable(torch.from_numpy(rev_chunk_batch).cuda(), requires_grad=False)\n",
    "    \n",
    "        unscaled_logits, _, outputs = model(\n",
    "            chunk_batch_torch,\n",
    "            output_mode='argmax', feed_mode='sampling'\n",
    "        )\n",
    "        eval_loss = loss_function(unscaled_logits.view(-1, vocab_size), rev_chunk_batch_torch.view(-1))\n",
    "        eval_acc = torch.mean(torch.eq(outputs, rev_chunk_batch_torch).float())\n",
    "\n",
    "        train_losses[run].append(train_loss.data.cpu().numpy().mean())\n",
    "        train_accs[run].append(train_acc.data.cpu().numpy().mean())\n",
    "        eval_losses[run].append(eval_loss.data.cpu().numpy().mean())\n",
    "        eval_accs[run].append(eval_acc.data.cpu().numpy().mean())\n",
    "        \n",
    "        cum_train_loss += train_losses[run][-1]\n",
    "        cum_train_acc += train_accs[run][-1]\n",
    "        cum_eval_loss += eval_losses[run][-1]\n",
    "        cum_eval_acc += eval_accs[run][-1]\n",
    "    \n",
    "        if (step + 1) % print_skip == 0:\n",
    "            print('Step', step + 1)\n",
    "            print('Train loss: {:.2f}; train accuracy: {:.2f}'.format(\n",
    "                cum_train_loss / print_skip, cum_train_acc / print_skip\n",
    "            ))\n",
    "            print('Eval loss: {:.2f}; eval accuracy: {:.2f}'.format(\n",
    "                cum_eval_loss / print_skip, cum_eval_acc / print_skip\n",
    "            ))\n",
    "            cum_train_loss = 0\n",
    "            cum_eval_loss = 0\n",
    "            cum_train_acc = 0\n",
    "            cum_eval_acc = 0\n",
    "        \n",
    "            outputs_np = outputs.data.cpu().numpy()\n",
    "            for i in range(decode_batch_size):\n",
    "                print('{}|  vs  |{}'.format(\n",
    "                    ''.join(list(map(id_to_char, chunk_batch[i]))),\n",
    "                    ''.join(list(map(id_to_char, outputs_np[i])))\n",
    "                ))\n",
    "            \n",
    "            print('{:.2f}s from last print'.format(time() - last_print_time))\n",
    "            last_print_time = time()\n",
    "            print()\n",
    "    \n",
    "    print('{} steps took {:.2f}s\\n'.format(num_steps, time() - global_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def running_average(a, alpha=0.99):\n",
    "    av = a[:1]\n",
    "    for el in a[1:]:\n",
    "        av.append((1 - alpha) * el + alpha * av[-1])\n",
    "    return av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_losses_av = []\n",
    "train_accs_av = []\n",
    "\n",
    "eval_losses_av = []\n",
    "eval_accs_av = []\n",
    "\n",
    "for run in range(len(train_losses)):\n",
    "    train_losses_av.append(running_average(train_losses[run]))\n",
    "    train_accs_av.append(running_average(train_accs[run]))\n",
    "\n",
    "    eval_losses_av.append(running_average(eval_losses[run]))\n",
    "    eval_accs_av.append(running_average(eval_accs[run]))\n",
    "            \n",
    "train_losses_av_mean[reinforce_strategy] = np.mean(train_losses_av, axis=0)\n",
    "train_accs_av_mean[reinforce_strategy] = np.mean(train_accs_av, axis=0)\n",
    "\n",
    "eval_losses_av_mean[reinforce_strategy] = np.mean(eval_losses_av, axis=0)\n",
    "eval_accs_av_mean[reinforce_strategy] = np.mean(eval_accs_av, axis=0)\n",
    "    \n",
    "train_losses_av_std[reinforce_strategy] = np.std(train_losses_av, axis=0)\n",
    "train_accs_av_std[reinforce_strategy] = np.std(train_accs_av, axis=0)\n",
    "\n",
    "eval_losses_av_std[reinforce_strategy] = np.std(eval_losses_av, axis=0)\n",
    "eval_accs_av_std[reinforce_strategy] = np.std(eval_accs_av, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss; mean: 0.75, std: 0.00\n",
      "Train accuracy; mean: 0.76, std: 0.00\n",
      "Eval loss; mean: 0.77, std: 0.00\n",
      "Eval accuracy; mean: 0.75, std: 0.00\n"
     ]
    }
   ],
   "source": [
    "print('Train loss; mean: {:.2f}, std: {:.2f}'.format(\n",
    "    train_losses_av_mean[reinforce_strategy][-1], \n",
    "    train_losses_av_std[reinforce_strategy][-1]\n",
    "))\n",
    "print('Train accuracy; mean: {:.2f}, std: {:.2f}'.format(\n",
    "    train_accs_av_mean[reinforce_strategy][-1], \n",
    "    train_accs_av_std[reinforce_strategy][-1]\n",
    "))\n",
    "print('Eval loss; mean: {:.2f}, std: {:.2f}'.format(\n",
    "    eval_losses_av_mean[reinforce_strategy][-1], \n",
    "    eval_losses_av_std[reinforce_strategy][-1]\n",
    "))\n",
    "print('Eval accuracy; mean: {:.2f}, std: {:.2f}'.format(\n",
    "    eval_accs_av_mean[reinforce_strategy][-1], \n",
    "    eval_accs_av_std[reinforce_strategy][-1]\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fec58424a20>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3XdYVFf+x/H3mQJD701AiooICojYjaJrSyxZTa+mm2Li\nmsS0TS+7m7r5qekxGlNN1Bg1mkSjxhIrih3FAtLr0IYZmHJ/f2DYWEEFhnJez+MTmHvvud8ZzYfL\nueeeIxRFQZIkSWpfVPYuQJIkSWp6MtwlSZLaIRnukiRJ7ZAMd0mSpHZIhrskSVI7JMNdkiSpHZLh\nLkmS1A7JcJckSWqHZLhLkiS1Qxp7ndjX11cJDw+31+klSZLapJSUlGJFUfwa2s9u4R4eHs7OnTvt\ndXpJkqQ2SQiR2Zj9ZLeMJElSOyTDXZIkqR2S4S5JktQO2a3PXZKk05nNZrKzszGZTPYuRWoFdDod\nISEhaLXaSzpehrsktRLZ2dm4ubkRHh6OEMLe5Uh2pCgKJSUlZGdnExERcUltyG4ZSWolTCYTPj4+\nMtglhBD4+Phc1m9xMtwlqRWRwS796XL/LbS5cM/PzmbTgzdTU2uxdymSJEmtVpsL96Pv/xOftbvZ\n++G/7V2KJElSq9Xmwr36xonYgPw96+xdiiRJUqvV5sJ9RM+ryfMGTV6RvUuRpHYnIyODHj16cO+9\n9xIbG8vo0aMxGo2kpqYyYMAA4uLimDRpEnq9HoDk5GSefPJJ+vXrR1RUFBs3bgTAarUyc+ZM+vbt\nS1xcHB999JE931aH1OaGQmpUGooDNIRlW1BsNoSqzf18kqQGvbT8AAdzK5q0zZhO7rwwIbbB/dLT\n0/nmm2/45JNPuP7661m8eDFvvPEGs2fPZtiwYTz//PO89NJLvPvuuwBYLBa2b9/OypUreemll1iz\nZg1z587Fw8ODHTt2UFNTw+DBgxk9evQlD+uTLl6bTMbaYH88K+H47i32LkWS2p2IiAgSEhIA6NOn\nD8eOHaOsrIxhw4YBMGXKFDZs2FC//+TJk+v3zcjIAODXX39lwYIFJCQk0L9/f0pKSkhPT2/ZN9LB\ntbkrdwCv+P6w5gcOrP6SLn0G27scSWpyjbnCbi6Ojo71X6vVasrKyhq1v1qtxmKpG8WmKAqzZ89m\nzJgxzVeodEFt8sp9wMR7sQkwHt5j71Ikqd3z8PDAy8urvj/9iy++qL+KP58xY8bwwQcfYDabAThy\n5AgGg6HZa5X+p01eufsFRLDPB5zyyu1diiR1CJ9//jn3338/1dXVREZGMm/evAvuf88995CRkUFi\nYiKKouDn58fSpUtbqFoJQCiKYpcTJyUlKZezWMeSaxIJPm4kYdtuHB10TViZJNnHoUOH6NGjh73L\nkFqRc/2bEEKkKIqS1NCxbbJbBoCIcNyNsG3d1/auRJIkqdVps+EeMnAcABmbltu5EkmSpNanzYZ7\n73G3UKMFkX7C3qVIkiS1Om023LU6HYVBavxzaqi11tq7HEmSpFalzYY7QE1oIJ2LIGXfT/YuRZIk\nqVVp0+Hu3mc0AHtXfWnnSiRJklqXNh3uncfdikWtUJuWjr2GdEqSJLVGbTrcwzsHUeGrpnOWmSP6\nI/YuR5IkqdVo0+EuhMAcGEBkPvyWtsze5UhSm2cwGBg3bhzx8fH07NmThQsXkpKSwrBhw+jTpw9j\nxowhLy8PgJSUFOLj44mPj2fmzJn07NkTgPnz5zNt2rT6NsePH8/69euBugnFBg4cSGJiItdddx1V\nVVUAhIeH88ILL5CYmEivXr1IS0sDoKqqijvvvJNevXoRFxfH4sWLL9iO9D9tcvqBvzJF90ezZykH\nNv+IMvBxuQal1D6segry9zVtm4G94Mr/XHCXn3/+mU6dOvHTT3WDFMrLy7nyyiv58ccf8fPzY+HC\nhfzzn//ks88+484772TOnDkMHTqUmTNnNnj64uJiXn31VdasWYOLiwuvv/4677zzDs8//zwAvr6+\n7Nq1i/fff5+33nqLTz/9lFdeeQUPDw/27av7LPR6fYPtSHXafLg7jpgMC5ficVzP7sLdJAYk2rsk\nSWqzevXqxWOPPcaTTz7J+PHj8fLyYv/+/YwaNQqoW4QjKCiIsrIyysrKGDp0KAC33XYbq1atumDb\nW7du5eDBgwweXDeTa21tLQMHDqzf/tepg5csWQLAmjVr+Pbbb+v38fLyYsWKFRdsR6rT5sO9R0Iv\nSlyhR47CkvQlMtyl9qGBK+zmEhUVxa5du1i5ciXPPvssI0aMIDY2li1bTl874ULTAGs0Gmw2W/33\nJpMJqJsGeNSoUXzzzTfnPO5cUwefS0PtSHUa7HMXQuiEENuFEHuEEAeEEC+dYx9HIcRCIcRRIcQ2\nIUR4cxR7LoEeOsp9vYjNtvHriZ8pr5EzRUrSpcrNzcXZ2Zlbb72VmTNnsm3bNoqKiurD3Ww2c+DA\nATw9PfH09GTTpk0AfPXVV/VthIeHk5qais1mIysri+3btwMwYMAANm/ezNGjR4G6/v0jRy48EGLU\nqFG899579d/r9fpLaqcjaswN1RpghKIo8UACMFYIMeCMfe4G9IqidAX+C7zetGVeWHF4D5yqBW4l\nJhYeXtiSp5akdmXfvn3069ePhIQEXnrpJV5++WUWLVrEk08+SXx8PAkJCfzxxx8AzJs3j4ceeoiE\nhITThiIPHjyYiIgIYmJieOSRR0hMrPtt2s/Pj/nz53PTTTcRFxfHwIED62+cns+zzz6LXq+nZ8+e\nxMfHs27duktqpyO6qCl/hRDOwCbgAUVRtv3l9V+AFxVF2SKE0AD5gJ9ygcYvd8rfv/r202+Jf+sl\nfr7Gj6Vxgl+u+QWdRk4DLLUtbXnK34yMDMaPH8/+/fvtXUq70uxT/goh1EKIVKAQWP3XYD8lGMgC\nUBTFApQDPo1puykEDU4GjcKQYzWUmkpZdkwOi5QkqWNrVLgrimJVFCUBCAH6CSF6XsrJhBD3CSF2\nCiF2FhUVXUoT5xQf5k2VtzNemWX08u3J/APzsdqsTda+JEkXFh4eLq/aW5mLeohJUZQyYB0w9oxN\nOUAowKluGQ+g5BzHf6woSpKiKEl+fn6XVvE5eDo7kO8fgrlMcFenMWRVZrH8uJznXZKkjqsxo2X8\nhBCep752AkYBZ969WAZMOfX1tcDaC/W3N4fSyN6gCAZn6Onl24vZu2djtBhbsgRJkqRWozFX7kHA\nOiHEXmAHdX3uK4QQLwshJp7aZy7gI4Q4CjwKPNU85Z6fpu8IACp2buGxpMcorC5kwYEFLV2GJElS\nq9DgQ0yKouwFep/j9ef/8rUJuK5pS7s43RJjUTRgOnyUPgF9GNl5JHP3z+WaqGvwdfK1Z2mSJEkt\nrk1PHPZXMSGeVHi6YMuvAKuZGX1mYLaZmb17tr1Lk6Q2Lzw8nOLiYruc+91336W6utou527L2k24\nuzpqKPALpkavRsnbT2f3ztzY/UaWHl0qpwOWpDZMhvulaTfhDlAckYBiVVGbsgaAqXFTcdG68E7K\nO3auTJLaji+//LL+KdWpU6ditVobtd3V1ZWZM2cSGxvLyJEj2b59O8nJyURGRrJsWd2zJ1arlZkz\nZ9K3b1/i4uL46KOPAFi/fj3Jyclce+21REdHc8stt6AoCrNmzSI3N5fhw4czfPjwlv0g2rg2P3HY\nX4n4wbDyOwwpW3G8Gjx1nkyNm8pbO9/ij5w/GBQ8yN4lSlKjvL79ddJKm/aR+mjvaJ7s9+QF9zl0\n6BALFy5k8+bNaLVaHnzwwdPmjTnf9ttvvx2DwcCIESN48803mTRpEs8++yyrV6/m4MGDTJkyhYkT\nJzJ37lw8PDzYsWMHNTU1DB48mNGj65bL3L17NwcOHKBTp04MHjyYzZs388gjj/DOO++wbt06fH3l\nvbOL0a7CPbR3LIoKjIeP1r92U/RNfJP2DW+nvE3/oP6oVWo7VihJrdtvv/1GSkoKffv2BcBoNOLv\n79+o7Q4ODowdW/cITK9evXB0dESr1dKrVy8yMjKAukU29u7dy6JFi4C6+eLT09NxcHCgX79+hISE\nAJCQkEBGRgZDhgxpkffdHrWrcI/p7E2Whwsu+aVQUwWOrjioHfhH4j+YuWEmy44tY1K3SfYuU5Ia\n1NAVdnNRFIUpU6bw73//+7TX58+ff8HtAFqttn6xHJVKVT+Fr0qlqp/CV1EUZs+ezZgxY047dv36\n9fX7Q8PT/koNa1d97p08dGR7dcKk16Lkpta/PiZ8DHG+cczZPYdqs7wxI0nn87e//Y1FixZRWFgI\nQGlpKZmZmY3e3pAxY8bwwQcfYDabAThy5AgGg+GCx7i5uVFZWXmxb6XDa1fhLoSgICweW60Ky97f\nT3v9saTHKDQWsuCgfLBJks4nJiaGV199ldGjRxMXF8eoUaPq10xtzPaG3HPPPcTExJCYmEjPnj2Z\nOnVqg1fo9913H2PHjpU3VC/SRU3525Sacsrfv3r//aUMn/U0nW7shseLp88OOWPdDDbnbmbl5JXy\nwSap1WnLU/5KzaPZp/xtS4ITe6EAxsPpZ237R59/YLaaeS/1vbMPlCRJakfaXbjHRvpT6eaMucAE\nVYWnbQtzD+PG6BtZkr6Eo/qj52lBkiSp7Wt34R7h60rmqZuq5Ow6a/vUuKm4aFx4O+VtO1QnSZLU\nMtpduKtVgrzQXliMaixpm8/a7qnz5N64e9mUs4ntedvtUKEkSVLza3fhDqDu0QsAU+qZqwHWuSn6\nJvyd/JmTOgd73VCWJElqTu0y3AOT4gAwHj4G5whvnUbH1Pip7C7czfqs9S1cnSRJUvNrl+Ee3S2E\nSmcnaoqsUHr8nPtM6jaJcPdw3kl5B7PN3MIVSpIkNa92Ge7dAlzJ8OxETdm5b6oCaFVaHu3zKBkV\nGSw+sriFK5QkqSVkZGTQs2fPJm/3X//6V5O32dTaZbg7atTkBsdQW6nBemzrefdLDk2mb2Bf3k99\nn8pa+XizJDXGmVMAd0RtIdzb1cRhf6WK7gE7lmPaswOX88wV9ue0BDeuuJHP9n/G9MTpLVukJJ1H\n/r/+Rc2hpp3y17FHNIHPPNPgfn//+9/JysrCZDIxffp07rvvPlxdXZk6dSpr1qzhvffeo6Kigkcf\nfRQXFxcGDx7M8ePHWbFiBS+++CInTpzg+PHjnDx5kv/+979s3bqVVatWERwczPLly9Fqtbz88sss\nX74co9HIoEGD+Oijj7BarQwcOJA333yT5ORknn76aVQqFa+99to56zxXG0IIUlJSuOuuuwDqpxMG\nGDBgAHPnziU2NhaA5ORk3nrrLWw2G9OnT8dkMuHk5MS8efPo3r078+fPZ9myZVRXV3Ps2DEmTZrE\nG2+8wVNPPYXRaCQhIYHY2Fi++uqrc35mAHPnzuX111/H09OT+Ph4HB0dmTNnDkVFRdx///2cPHkS\nqFuQZPDgwZf193umdnnlDuCbUHdT1ZSeAdbz96nH+sQyPnI8Xxz8gryqxs+RIUnt1WeffUZKSgo7\nd+5k1qxZlJSUYDAY6N+/P3v27CEpKYmpU6eyatUqUlJSKCoqOu34Y8eOsXbtWpYtW8att97K8OHD\n2bdvH05OTvz0008ATJs2jR07drB//36MRiMrVqxAo9Ewf/58HnjgAdasWcPPP//MCy+8cN46z9UG\nwJ133sns2bPZs2fPafvfcMMNfPfddwDk5eWRl5dHUlIS0dHRbNy4kd27d/Pyyy/zzF9+AKamprJw\n4UL27dvHwoULycrK4j//+Q9OTk6kpqbWz3V/rs8sNzeXV155ha1bt7J582bS0v73w3r69OnMmDGD\nHTt2sHjxYu65557L+Bs7t3Z75d49NpxqR0dqSquh4AB0Sjjvvo/0foRfM35l9u7Z/OuK1v/rltT+\nNeYKu7nMmjWLH374AYCsrCzS09NRq9Vcc801AKSlpREZGUlERAQAN910Ex9//HH98VdeeWX9PO5W\nq/W0Od7/nNd93bp1vPHGG1RXV1NaWkpsbCwTJkwgNjaW2267jfHjx7NlyxYcHBzOW+e52rjiiiso\nKytj6NChANx2222sWrUKgOuvv57Ro0fz0ksv8d1333HttdcCdXPKT5kyhfT0dIQQ9TNWQt0smB4e\nHkDdpGmZmZmEhoY26jPLz89n2LBheHt7A3Dddddx5Ejdkp9r1qzh4MGD9cdXVFRQVVWFq6trw39B\njdRuwz06yIOVHp3w0ldBTsoFwz3INYjbYm5j7v653BpzKzE+MS1YqSS1HuvXr2fNmjVs2bIFZ2dn\nkpOTMZlM6HQ61OrGLXTz13ncz5zj3WKxYDKZePDBB9m5cyehoaG8+OKLmEym+uP37duHp6dn/bTC\n59JQG+cSHByMj48Pe/fuZeHChXz44YcAPPfccwwfPpwffviBjIwMkpOTz3ovcP455s/3mV2IzWZj\n69at6HS6C+53Odptt4yLo4acoChqyjXYMhueffLuXnfj5ejFWzvfkg82SR1WeXk5Xl5eODs7k5aW\nxtatZw9I6N69O8ePH6+/Cl+4cOFFnePP4PP19aWqqqp+VSaAJUuWUFpayoYNG3j44YcpKyu7qDY8\nPT3x9PRk06ZNAKctEQh1XTNvvPEG5eXlxMXF1b/n4OBg4H+LkjREq9XWX+Gf7zPr27cvv//+O3q9\nHovFwuLF/xuVN3r0aGbPnl3/fWpqKk2t3YY7AN26gyKo2bejwV3dHNx4IOEBduTvYEP2hhYoTpJa\nn7Fjx2KxWOjRowdPPfUUAwYMOGsfJycn3n//fcaOHUufPn1wc3Or77poDE9PT+6991569uzJmDFj\n6pfsKy4u5qmnnuLTTz8lKiqKadOmMX36uQc5nK8NgHnz5vHQQw+RkJBw1oXatddey7fffsv1119f\n/9oTTzzB008/Te/evRu9+tN9991HXFwct9xyy3k/s+DgYJ555hn69evH4MGDCQ8Pr/+cZs2axc6d\nO4mLiyMmJqb+t4im1O7mc/+rBYs20vfZ+wjsW4bXJ4dB537B/c02M5N/nIwQgsUTF6NVaZu1Pkn6\nq7Y0n/uf/cOKovDQQw/RrVs3ZsyYYe+yWp0/PyeLxcKkSZO46667mDSp8Ut9yvncz6NrXHdqNFpq\n9FrIa/jXHq1Ky4w+MzhRfoIlR5a0QIWS1DZ98skn9UMBy8vLmTp1qr1LapVefPFFEhIS6NmzJxER\nEfz9739vsXO32xuqADEhnqz16ISH3lB3UzViaIPHDA8dTlJAEu/veZ9xkeNwdWi6u9eS1F7MmDGj\nxa7UJ02axIkTJ0577fXXXz9rke3W6K233rLbudt1uHs6O5AV2IUeaZkomTsQQxo+RgjB40mPc+NP\nN/Lpvk/5R59/NH+hknSKoij1o0ukOn8OMexoLrfLvMFuGSFEqBBinRDioBDigBDirDscQohkIUS5\nECL11J/nL6uqJmTpFg1WMO3dfs4ZIs8l1jeWiV0m8vmBzzlUcqiZK5SkOjqdjpKSEjlaS0JRFEpK\nSi5rqGRjrtwtwGOKouwSQrgBKUKI1YqiHDxjv42Kooy/5EqaiU/fRFgKpmwDTiVHwbdbo457ou8T\n/JH7B//c/E8WjluIVi1vrkrNKyQkhOzs7LOe+JQ6Jp1OR0hIyCUf32C4K4qSB+Sd+rpSCHEICAbO\nDPdWqWdiNBWOzniUVOOVsanR4e7h6MELA1/g4bUP8+HeD3m498PNXKnU0Wm12vqnPiXpcl3UaBkh\nRDjQGzjXEkcDhRB7hBCrhBCx5zn+PiHETiHEzpa6OukZ4kmadziGUh1knr3s3oUkhyYzsctE5u6b\ny4GSA81UoSRJUtNrdLgLIVyBxcA/FEWpOGPzLiBMUZR4YDaw9FxtKIrysaIoSYqiJPn5+V1qzRdF\np1VTHh6FpUKF9fDmRve7/+nJfk/io/Ph2U3PUmutbaYqJUmSmlajwl0IoaUu2L9SFOWsAeCKolQo\nilJ16uuVgFYI4duklV4Gp/i6eWWMmSWgz7ioY90d3Hlh0AscLTvK+6nvN0N1kiRJTa8xo2UEMBc4\npCjKO+fZJ/DUfggh+p1qt6QpC70cnQclYQOMJdqL7poBGBoylEldJzHvwDw2Zm9s+gIlSZKaWGOu\n3AcDtwEj/jLU8SohxP1CiPtP7XMtsF8IsQeYBdyotKLxXIk9QjjpFoBB7wIZFx/uAE/1e4punt14\nYsMTHC8/97qskiRJrUVjRstsAi74VIWiKHOAOU1VVFPzc3MkJyiSsMwilIxNF34z5+GsdWbWiFnc\n9NNNPLL2Eb666is8HBs/WZIkSVJLatdzy/yVLToWUWPDnJ0D5dmX1EYn1078N/m/5FTlMPP3mVhs\njZtBTpIkqaV1mHD37dsHAGOJwyV3zQAkBiTy3IDn2JK3hbd3vt1U5UmSJDWpDhPuMYMSMKodqNK7\nQOamy2prcrfJ3NLjFr489CUf7/1YPi4uSVKr064nDvurqCAPlvh0xqnkJMGZf1x2e48nPU55TTmz\nd8+mvKacx5MelxM+SZLUanSYcFepBOVdemDbegxbQSaqynxwC7zk9jQqDa8NeQ03BzcWHFxARW0F\nLwx8AY2qw3ykkiS1Yh2mWwbAOT4BlaJgLNVCxuV1zQCohIqn+z3N/fH3s/ToUqatnUaNtaYJKpUk\nSbo8HSrcw5MHYkNQVeIGx9Y1SZtCCB5KeIjnBjzHHzl/MO23aRgtxiZpW5Ik6VJ1qHCPjwklwyOI\n0hJvOLoabLYma/v67tfzyuBX2J6/nQfWPEBlbWWTtS1JknSxOlS4OztoyAnrgTXfhFJeAPl7mrT9\nq7tezetXvM6ewj3c8fMdFFYXNmn7kiRJjdWhwh1AlZCI2mKlutQB0lc3eftjI8by3t/eI6syi9tX\n3U5WZVaTn0OSJKkhHS7cu/xtMABlVZ3hyC/Nco5BwYOYN2YeVeYqbl91O/uL9zfLeSRJks6nw4V7\nv4QuZLgHUpzvDDkpYChulvPE+sby+djPcVA5cPuq21l0ZJF82EmSpBbT4cLdxVFDYUQMIqccxabA\n0d+a7VxdPLuwcPxCkgKSeGnLSzy6/lH0Jn2znU+SJOlPHS7cAZz69kVrMVNd7Q/pzdM18ydPnScf\njPyA6YnTWZ+1nvE/jOfbtG+xKU03UkeSJOlMHTLcY8YMBSCvIrzuyt3avLM7qlVq7ul1D99P+J4e\nPj14bdtrTFk1heNlcl54SZKaR8cM99gIctwDKMoETGWQvaNFztvVqyufjPqE14a8xomKE1y7/Fo+\n3PMhZqu5Rc4vSVLH0SHDXaUSlMQk4pKVj9WqhvRfW+zcQggmdpnIj1f/yN86/433Ut/jhp9u4GDJ\nwRarQZKk9q9DhjuAR/IwtDYLpeZecGg5tPBIFh8nH94c9iazR8ym3FTOLT/dwkd7PqLWWtuidUiS\n1D512HDvPX44JrWWk9neUJIO+XvtUkdyaDJLrl7CyLCRzEmdw8SlE9mSu8UutUiS1H502HAP8HXn\naEgPao8UoQgN7PvebrV4OHrw5rA3+WjURzioHbh/zf3M3j1bXsVLknTJOmy4A1iSBuBZUYLJcwjs\nX9KkE4ldikGdBvHtuG8ZHzmej/d+zN2/3M2J8hN2rUmSpLapQ4d72JUjATie1wkqcuCk/btDnLXO\nvDbkNd4c9ibpZelMXjaZd1PepaK2wt6lSZLUhnTocE/sH8NJ9wCK9xaC1hn2L7J3SfXGho9lxaQV\nXBVxFXP3z2XwN4O5ccWNrD25Vk5jIElSgzp0uOu0avJ69sfnRBrmkJFwYCm0ojHnvk6+vDbkNb64\n8gseiK+bI376uuncuupW2V0jSdIFdehwBwiacCVqxcbRnBAwljbZCk1NKcE/gQcTHuTHv//Iy4Ne\nJqM8g2uWXcMHez7AbGs9P4wkSWo9Ony4D7lqMIXOXuRsywSdZ6vqmjmTRqVhUrdJLL16KSPDRvJ+\n6vtM+GECP5/4GavNau/yJElqRTp8uLs4asmLG4B/+l7MEePg0AqorbZ3WRfk5+zHG0Pf4IORH+Ck\ncWLmhpncuvJWjuqP2rs0SZJaiQbDXQgRKoRYJ4Q4KIQ4IISYfo59hBBilhDiqBBirxAisXnKbR5B\nE65Ca7NyMCsQzAY48rO9S2qUIcFDWDRhEf8a8i+yqrKYvGwyj6x9hDWZazBZTPYuT5IkO2rMlbsF\neExRlBhgAPCQECLmjH2uBLqd+nMf8EGTVtnM+k8Yhl7nTvYfx8AtCPa13q6ZM6lVaiZ0mcCyvy/j\nvrj72F24mxnrZzBq0Shm755NsbF5FiORJKl1azDcFUXJUxRl16mvK4FDQPAZu10NLFDqbAU8hRBB\nTV5tM9E5aCmI60+nw6nUdp1YN5FYZYG9y7oo3jpvpvWextrr1vLxqI/p7d+bT/Z+wuhFo3l207Mc\nKjlk7xIlSWpBF9XnLoQIB3oD287YFAz8dSXobM7+AdCqdZpwFTprLSnZ4WCzQMo8e5d0SbRqLQM7\nDWTWiFksn7Sca7pdw6+Zv3L9iuuZsmoKK46voKq2yt5lSpLUzERjH4gRQrgCvwOvKYqy5IxtK4D/\nKIqy6dT3vwFPKoqy84z97qOu24bOnTv3yczMvPx30EQsNbXs6juQnO6JTJpYAkVpMH0vqDX2Lu2y\nldeUsyR9CV8e+pLC6kIcVA4MCh7E6LDRDOw0EF8nX3uXKElSIwkhUhRFSWpwv8aEuxBCC6wAflEU\n5Z1zbP8IWK8oyjenvj8MJCuKkne+NpOSkpSdO3eeb7NdrLz1Qfz2bCV2/tM4L78HbloI3cfau6wm\nY1NspBam8mvmr6zOXE1hdSEAPbx7MLDTQJJDk0nwS0AIYedKJUk6n8aGe4OXpaLu//S5wKFzBfsp\ny4BpQohvgf5A+YWCvbUKmnAlup3r2LDLxljXANj5WbsKd5VQkRiQSGJAIk/0fYK9RXvZnr+dTTmb\nWHBwAZ/t/4yunl0ZFjKMaJ9oojyjiPCIkGEvSW1Qg1fuQoghwEZgH/DntInPAJ0BFEX58NQPgDnA\nWKAauPPMLpkztcYrd1tNDTv7D+FEaDQ3zIiGDW/C9FTwCrd3ac3OYDaw8sRKfjr+E3sK92BR6taV\nDXULZWIoybffAAAgAElEQVSXiUzqOokAlwAURZFhL0l21KTdMs2hNYY7wG/TnsZv7XIcvphH9E9j\nYcADMPpVe5fVogxmAzlVOfVdONvy6u6fB7oEUmosJdAlkL6BfUkKTCIpIIkA5wAZ+JLUQmS4X6Li\nPQcouuFadky4k9v7HYKjv8GM/aBzt3dpdpNRnsFvJ3/jiP4IPk4+ZFVkkVKYQmVtJQA+Oh96+vak\nf1B/unh0wUvnhZ+zHy5aF5w0TnauXpLalybrc+9ofONjORgcie/GX6l+6D84H1hSNyxy8FkP5nYY\n4R7h3N3r7tNes9qspOnTSC1M5UDxAVKLUvk9+/fT9lEJFfF+8ST6J9IvsB+9A3rLsJekFiKv3M9h\n73tz0c5+i/0vzOY682woPFQ3LFKrs3dprZaiKGRWZFJiKkFv0lNYXUh+dT4p+SkcLDmIRbGgUWmI\n94unb2BfIj0iSQ5NlmEvSRdJdstcBmtFBQcGDmFT90FMfeNG1F9eDRP+D/rcYe/S2iSjxciO/B3s\nLNjJHzl/cFh/GAAHlQMJ/glcFXEVg4MHE+gSaOdKJan1k+F+mbbfMw22/UH5/CWMSrkTqkvg4RRQ\na+1dWptXY61hb9Fe1p5cy+/Zv5NVWfdwcyeXTlwRcgVDQ4YS7BpMkEsQzlpnrDYrapXazlVLUusg\nw/0yVWzdRs4dd/DjyDt46pEE+Pp6mDAL+kyxd2ntiqIoHCw5yObczaSVpvF71u/U2moBEAi0Ki21\ntlpifGIYEDSAMPcwMisyqbXWEugSSFfPrnT17EqAS4Cd34kktQwZ7pdJURR2jhpHmb6SgMVLiFt9\nI1QVwMO7QONg7/LararaKo7oj5BvyCejIgOTxYRGpWFb/jYOFtf13auFGp1Gh8FsqD/OW+dNlFcU\noW6hBLsGMzp8NCGuIXKIptTuyHBvAoUrf6bk0Rn8Onka0++Khi8n1415H/SwvUvrkKrN1eRW5RLu\nEY5GpUFv0nO07ChppWmk69NJK00j35CPvkYPgJejF9He0fg4+eCj88HD0QOT1cTO/J0c1h/GptgI\ndw9nQpcJxPnF0dWzKy5aFzu/S0m6MBnuTUCx2dg5bCS5ZjXRPyyi+9p7IXMzPLQdPNrUpJcdSlZl\nFptzNnOo9BCHSw9TVlNGYXVh/Xqz3b26kxiQiFqo2VO0h33F+wBQCzVdPbvSxbMLf+v8NwYHD5Zh\nL7U6MtybSM4XX1Px2issveYfPP3YaHh/APSYCNd8Yu/SpIugKApmm7muH/+Mm+Inyk+QWZHJ3qK9\nHCw9SFpJGiWmElRCRXev7iT4JxDtHV3fv++sdbbTu5AkGe5NRjGb2Tl6PFXllbh9s5ik7E9g49tw\n16/Qub+9y5OagdVmJaUghR0FO9hdsJu9xXsxWoz124Ndg+nm1Y1unt3q/xvmEYZWJUdSSc1PhnsT\nKt30BwX33M3a/hN58KN/Ij4YBBpHuH8TaOVDOO2dTbGRU5lDelk66fp00svSOao/SkZFBlbFCoBG\npSHCI4Kunl2J8ooiyisKPyc/unp1laEvNSkZ7k1s8+3347JzM2Xvf0Fy5zJYcDUMnAZjXrN3aZKd\n1FprOVF+oj7s//xvriG3fh+NSkOQSxDh7uGEuIXgonUhxDWE3v698Xf2x9XB1Y7vQGqLZLg3MWNO\nLmljruRYaAzXrPwasfJx2DEX7lwFYQPtXZ7UiuhNerIqs8ityuVQ6SFyqnI4Xn6cnMocaqw19Vf7\nAAHOAfQJ6EOsTyxBrkH46Hzo7N4Zb503KnFRq2BKHYQM92aw9oW3CFo4l7yn/82IG0fCB4NAqOCB\nzeAgR1VIDVMUhYyKDFILU9HX6DlUcoiUghSKjEWn7efu4I6bgxu+Tr5EeUXhoHbAWeNc/1qoWygh\nbiF4OHrIbp8ORoZ7M7CYatg8bAyKzUb/9b/gVJQC88dBv6lw1Rv2Lk9qw/QmPQXVBRRVF3G8/DgZ\nFRkYLUZyq3I5UX4Ci81CtaUam2I77TiVUBHoHEiwWzAhriGEuIUQ4hpCJ9dOWBUrJcYSHNWOeOu8\nCXINkr8RtAMy3JvJtu9W4v78YxybeBvj33gGVj0J2z6EKSsg4gp7lye1Y4qiYLQYKawu5GTlSXKq\ncigxlpBTlUN2ZTbZVdkUG4sv2IZGaAhwCSDKKwpfJ1+6enbF09ETbydv4nzj5DDPNkCGezNadvVt\nhKfvxueTzwjuGwsfDgGbBR7YAo7yBplkP39e7edU5aARGnycfDBajOhNenINuZQYS8isyORY2TGK\njEVU1FbUH6tVaevn6QlzC8NB7YBFseDv5I+L1gVvnTcuWhcc1A6Ee4Tj7tBxF7CxJxnuzSjjRC4Z\n11yHs1ZF4sqlaAzp8NnYuimBJ7xr7/IkqVEURaGguoBqczX5hnw2527mWNkxcqpyyK3KxapYUQlV\n/ZO9Z4rzjcPN0Y0CQwFGi5Faay0Oaof6/wY4103mFugSSJxfHNHe0YS4huDr5Iu+Ro/RYiTIJQiN\nSq4ZdDFkuDezDz7+iQH/9zQOPWLo8fUCVOtfgT9mwaSPIf4Ge5cnSU2mwFBArbWWImMRNdYaKmor\n2JG/g3R9OkaLkQDnAFwdXNGqtFhsFhzUDlRbqimqLqLWVkteVd5ZN4z/5Kp1JcIjAl8nX2pttYS6\nhhLpGUmYexjeOm88HT1bxRq9FpuF8ppyFBRqrDX46HzQaeyzeI8M92ZWVWPhqYff4aEN83CbPJmQ\nV16ELyZB9g6462fo1NveJUpSq5FvyCddn05uVS751fn4OvniqHYkrTStfgUvjdCQVZlFlbnqtGO9\ndd5467zxcPQg3D2cKK8onLXO9c8ONNdN4lprLd8f+Z5lx5ZxsOTgadtUQoWvky8x3jFE+0ST4JdA\nb//eLXLPQoZ7C1h3uJDfH3+JG9LXEjJnNm4DE+DjZLBZ4Y4V4NPF3iVKUpvyZ1dRTlUOepOeImMR\nB4oPkGvIxWg2klWVRXlN+WnHaFVaunh2oYd3D4Jcg9AITf2Vvtlmxt/JHw9HD4Jcg+jk0glPR8/z\n/iZgU2yk69PZmreVBQcWUGgspId3D4aGDMVb5w2Ak8aJXEMuOZU57C3eS2ZFJlC3sli8fzwjO48k\n3j+ecPfwsyaes9qsrDyxklifWCI9Iy/pM5Lh3kJeXpJK/Bsz6Varp+uypThoTj296uAMd68GN7l0\nnCQ1lfr7BJZq0vXplBhLyDPkkVaaxuHSw/XTPV+Ig8oBtUpNlFcUER4RuGhdUAkVx8uOc7DkYH0b\nPX168nDvhxkUPOiC7dVYa9iau5Ud+TvYlLOJY+XHgLqRSWHuYVgVK6WmUnycfKg2V1NQXcBN0Tfx\nTP9nLukzkOHeQgw1Fm58+QdeXvYvPKK7ETZvHurywzB/PHhHwp0/gc7D3mVKUrunKAoWxYKiKCgo\nKIqCSqgoNhZTVlNGXlUeuYZciqqLMJgNHC07SlZlFkaLkRprDV09uxLpGcmAoAEkBSQR4hZySXVk\nVmRyVH+UPUV7yKrMQq1S4+HgQa4hFyeNE2PCxzCy88hLXjpShnsLWnOwgE9fn89zOxbgmpRE6Ccf\no8raCF/fAGGD4JZFdRONSZLUKimKYvebto3V2HCXj6o1gZExAURNHsdbvW+kevt28p59DiVyBFz9\nPpzYAD9MBZut4YYkSbKLthLsF0MOMG0iL0yI5VGjmfnVeu5YvhyhVhP06iuIqgJY/Ry4BsDY/0A7\n/EckSVLr02C4CyE+A8YDhYqi9DzH9mTgR+DEqZeWKIryclMW2RaoVYI3r41nSrmJr7Fx89KlIARB\nr72KqMyHre+Bqz9c8Zi9S5UkqQNozJX7fGAOsOAC+2xUFGV8k1TUhjloVHxwWx+urjDhpBFM+uEH\nbCYjwf/5T90V/G8vg9kIw/8pr+AlSWpWDYa7oigbhBDhzV9K++Dp7MCntycxudKEhxZGrPqZHIuV\nTq/PQqV1gg1vQlUhXPUWaBzsXa4kSe1UU/W5DxRC7AFygccVRTnQRO22Sd0C3Pi/mxO553MbeHkz\nYvXXnCwsJGTObDSu/nVrsBYcgBu+BPcge5crSVI71BSjZXYBYYqixAOzgaXn21EIcZ8QYqcQYmdR\n0bnnmmgvRkQH8NLEWN50S2TzzTMwpaWRPWMG1n4z4LrPoSgNProCjvxi71IlSWqHLjvcFUWpUBSl\n6tTXKwGtEML3PPt+rChKkqIoSX5+fpd76lbvtoHh3DMkglerg9l78zSMqXvIvOVWzD4D4O5f60bQ\nfH193Zzwllp7lytJUjty2eEuhAgUpwaJCiH6nWqz5HLbbS+euaoHk3sH84Q+iO1Tn8Ock8OJ664j\nb85Ciq03Yo6+vW6xj3ljoeykvcuVJKmdaPAJVSHEN0Ay4AsUAC8AWgBFUT4UQkwDHgAsgBF4VFGU\nPxo6cXt6QrUhFquNJxfvY/GubF7upWPwl29Te6Ju5KjK2ZnOL9yB04HX60bQjHsHel0rR9NIknRO\ncvqBVsZqU/jHwlSW78nlroGhPJHojS0/j9ynnsaq1xPy72dxyXofsrdD3A0w/r9y0W1Jks4ipx9o\nZdQqwbs3JHDX4Ag+25LFQ7/lYYvrTdjXX6ENDubk4y9QqpuCMuxp2LsQ/i8Btn4Ilhp7ly5JUhsk\nw70FqVWC5yfE8Orfe7L+SBHXfvAHRY7uhH31Jc4JCRS8+hoFG83YbvsJ/LrDz0/C+wPh+O/2Ll2S\npDZGhrsd3DogjHl39CVHb+Tq9zZzuAo6fz4fz+uuQ//112TO/C+WcfPg1iWAAgsmwpKpYLjwyvaS\nJEl/kuFuJ0Oj/Fj84CC0KsGtc7exL7eCwJdfIvjdd6k5doxj4ydgKHaBB7bA0Cdg/2KYkwTbP6lb\n6UmSJOkCZLjbUVSAG1/e0x9nBzXXfriFD38/jvvYMYR/+w0aLy+ypt6PfulylGFPwQObwT8GVj4O\nHwyGgz+CnW6GS5LU+slwt7NIP1cWPzCIEd39ef3nNF74cT9KlyjCvv4Kp4QE8p97nqPJwyn6djXm\nKz+D6xeAzQLf3V63nF95tr3fgiRJrZAM91YgwF3HnJt7c8egcBZszeS6j/6gQOVE58/mEvTvf2PR\n6yl+7z2OXTWOwl9OYL3lVxj3NmTvrLuK3/aRfMJVkqTTyHHurcxvhwqY/m0qOq2KOTcnMiDSB0tJ\nCdU7dlLx009Url6N2tubTv/+F649Q2D5dMjYCF7hcMXjEH8TqOUaLJLUXsmHmNqwo4WV3LsghRPF\nBqYMDOPpq3qg09Ytpms6dIjsaQ9jzslBFxeH/4x/4OxdgVj3CuTvg0694co3IbSvnd+FJEnNQYZ7\nG1dVY+HtXw8zb3MGPYPdefeG3nT1dwXAZjJR9v0iSj7+GEtREdrgYAKffw5Xn2L4+Rmoyq97yvWK\nx+rGy0uS1G7IcG8n1hwsYMZ3qRhqLNwxKILHRkfh4ljX7WIzGKhYvZrSuXOpST+K2ssLx8hw/IZ6\n45T/HUKpgagroc8dEHGFnM5AktoBGe7tSHFVDf9dfYSvt5+kk4cTL18dy4ho//oV220GAyfvm4ql\nuAhzZt3Mko7duxE4PhLn0h/BWApaF4i5Gq54FHy72fPtSJJ0GWS4t0MpmaU8uXgfRwuriAvx4P5h\nXRgTG4ha9b8ZJC2lpVStW0/R7NlY8vNxiIzAa3QSrp65OOSsBIsRwodAwq3QbRQ4e9vxHUmSdLFk\nuLdTNRYri1Ny+HjDMTJKqokOdGP2Tb3pFuB22n626mrKvv+ekk/nYikqQjg743vXbbgHFqFKX46t\nOBuLxQmn5EmIuMkQMQxUaju9K0mSGkuGeztntSms2JvLS8sPUmE0MzG+EzPHdifIw+m0/RSrFdO+\nfRS+81+qt28/qx21ow2XgBqcQzXoBo1H1ecGHBMGttTbkCTpIslw7yAKK018uP44X23LxEGj4qkr\no7khKRSN+uzn00xHjmBMTcVaXo6tuhq1hwfVW7dQtX7Dafu5xXoR9OILqHuNaam3IUlSI8lw72Ay\nig08tWQvW4+XEubjzMwx3RnXK6j+puuF2Kqrqc3MxHxkN8bfvqdk9SGEAK23I25D+uH9j+fQBHZu\ngXchSVJDZLh3QIqisOZQIe+sPsKhvAp6d/bkufExJHb2uqh2jHt2UfbeK5iPH8KQDQhwiXTH+9qr\ncLluGsL1nOufS5LUAmS4d2AWq43vU7J565fDlBhqGRsbyMyx3eni53pxDdls1Gxaiv7zT6jYlYHV\nCFoXK+69/HBMSsb1hmmo/YKa501IknROMtwlKk1m5m46wacbT2A0WxnS1ZcrewYytmcgns4OF9WW\nUlND2bxZVK76CcORAlAAoeDW1Qm/2yfikDgcERADLn5ycW9JakYy3KV6xVU1fLzhOL8cyCezpBqN\nSjAi2p+ZY7qfNYSyMWwGA6b131H65ddU7v7flMPe3avwTVKj7j4UQgdA9FV1E5pJktRkZLhLZ1EU\nhQO5FSzfk8s3209SXWvl3qGRPJjcBTed9pLaNBcUUP7dV1T+/DOmY1kItcAtQsHFW4+zfy3aXlcg\nBj4EXUeCSs4wLUmXS4a7dEGlhlr+vfIQ36dk4+Ws5f5hXbh9YDhODpf+IJNx71703y6kcvVqbJWV\nAKi0Cq5BJrzidDj1iEQEdIceEyBsMGgcm+rtSFKHIcNdapTUrDLeWX2EDUeK8HV15P5hkSSGeVFe\nbaarvyuh3s4X3aaiKJgOHsS4Zw+m1N1U/vorNlMtKkeBW2gNHqEVOAVoEBF9Eb2ug+hxchoESWok\nGe7SRdmRUco7vx5hy/GS016PD/Hglv5hTEoMRnuOB6Maw1ploGLVSgwbNlD1+waU2rpVo9Q68O5W\ngVArWLWBuP1tJA5Db8SYU42lIB+VmzsqJx0uQ4YgZJeOJAEy3KVLtD+nnPxyEx7OWnZklLIsNZe0\n/Eo6ezszZVA4k3sH4+VycSNt/spmNFLxyy9Y8gsw7t5N1e+/N3iMy5AheN14A2ofH5zi42XQSx2a\nDHepSSiKwm+HCnn71INRbo4arukTwoBIHwZ19cH9Em/E/sl06BC1mSdx6p1A5fLF2DJTcFKfQGvY\ni7UGjHp3CnfrUCx1/06Fkw6XAQPRBgVh0Zdi2LQZ/8cew3PyJITDpf/QkaS2Qoa71OTS8it459cj\nrD9SRK3FhouDmqFRftw9JIKk8CbuMzeVw+FVkLUd87E91KYfwVJlpirXEVOFK7VlNlSuzthMtWCx\noAkMxOvmm/G4eiLagICmrUWSWpEmC3chxGfAeKBQUZSe59gugP8DrgKqgTsURdnV0IlluLddNRYr\nu0+WsWRXNqsPFqCvNpMU5sVtA8MY2zMQR00zTB1ss0HRITi+HlK/xpp9AKFSECowVHehZJ+W6owK\nhKMjPvfei+9DDzZqXh1JamuaMtyHAlXAgvOE+1XAw9SFe3/g/xRF6d/QiWW4tw/VtRa+25HFZ5sz\nOFlajZezlsmJIQzv7s+gLj6oVM0UsKUnIGMjlOdA7m4o2I8xo5Ci/V4YcjU4RYXS6Z1ZOHSNbp7z\nS5KdNGm3jBAiHFhxnnD/CFivKMo3p74/DCQripJ3oTZluLcvNpvC5mPFfL3tJL8eLMBqU/B01jK0\nmx93DA6nd6hn815JKwpkbkbZOY/SH9dRvFuLzaLCwUeDR7w/Tr37UJ1ZhumkHrV/J1TuPjhEdkEX\n0wONfwDa4E7ySl9qE1oy3FcA/1EUZdOp738DnlQU5azkFkLcB9wH0Llz5z6ZmZkNnltqe/SGWjYe\nLeb3w0WsOVRAudFMdKAbtwwI47o+Iei0zbzik82GeedPlH3xMVX7T2LKq63fpHGyYjMLbFZV3fw4\np6h9fPC97148b7gBlU7XvPVJ0mVoleH+V/LKvWMoNdSyZFc2P+zO4UBuBa6OGoZG+TK8uz9Do/wI\ncG/+IDXn5GDavRVtgA86fwfI34dycBnm/VuprVRTa/GmLE2hplSFUCn4DXHD6+abUCXdBq5+zV6f\nJF0M2S0jtTpbjpXwY2oO6w4XUlBRA0CQh47k7v6M7OGPp7MDBRUmyqrNRAe5ER/iedri302uLAv2\nfQ+lx1CElqoj5ZSsS8d4rARUCjovMy5dPHEbNRqLVxL6JT9hqzbiMmQIDmFhuI0YjsrF5bQmjamp\nqNzd0QYFIXQ6rMXFCJ0OtdvFT9AmSefSkuE+DpjG/26ozlIUpV9Dbcpw77j+nMBs24lSUjJL+f1w\nEYZa61n7hfk4c3V8J66KCyI60L3FajNs3EjRW69jSj9R15d/ASpXFxyjuuPcJ5Hak1lU/vLL2TsJ\ngWO3brhPGI/HhAloAwObqXqpI2jK0TLfAMmAL1AAvABoARRF+fDUUMg5wFjqhkLe2VCXDMhwl/6n\nxmIlJVNPpclCsKcTLo4aUrP0fLcjm20nSrApEOnnQmJnL0ZE143CcXHUsDe7HHedhkg/12a7wq89\neRLDz4ug6BBOHhXoAl2wFZ2geu9hDDlqrLUqKrKdUCwClaMajYcOzxF9sKgDsFZbcAgLQ7FaMGzY\niHHPHoROh9/D0/C69VZUjnLiNOniyYeYpHahuKqGn/bm8fuRInad1FNWbQZAJcB26p9uiJcTk3sH\nMy6uE90DW6j7w1IDRWmQvRMlby+Wg1vQOJgQ5gow6uv28Y2qm/0yKA6cfampcqZw3mKq1q1H27kz\nAU8+geuwYQiNpmVqltoFGe5Su2Ox2tieUcrWYyVk6Y0Mi/Kj1mpj6e4cth6vu8If1MWH65JCGNLV\nDz83O10ZlxyDQ8shczOc3Ao1FfWbFAUMhggKtgpqi02oXXU4hgZiqzXjEBaC/303o1WK6nZ2DYDQ\nvqDzOO+pbCYTFStWUL17N2pX17r+/uBg3EaMQOXmJod3tkMy3KUOpbiqhkUp2Xz+RwZ55SY0KsHQ\nKD+u6OZLTJA7PTq5X/Y8OJfEZoWK3Lo/RWlQngW5u1EKj1J5uJzKDIXaCg0mfd28OCqNDbfORrTO\nVqy1KkBg0wVjcwlFExCEQ2gQLsNGgs4T/bcL0X/zDVitCK0WodViq64+7fQOkZF4XnstHldPxJyV\nRc3xE2hDgnHu0wehbuYhqVKzkOEudUgWq420/EoWpWSzNq2Qk6V1YadWCfqGezExPpgufi509nEm\nyMPJztUC1aVQVQhmA7UnjlL02WIqth0EqxVUApWDBpWqFpXGgqVajc1y+oyYLtE+OHcPw+eWvyP8\nolA8u2FMO4xh8x/UHDuKYcNGbAbDWafVBAbiffvteN8xRc6y2cbIcJckIKu0mmNFVWw/UcqKvXn1\nYQ/Qzd+VK3sGMiDSh9hgDzyc7HBlfw7WKgNYLag9TnXHWM2QsRGlxoA5Nx/D1u0I/WGcdIU4elrA\nUPS/gx1cwdEdtDqoNaAYKzAZfMndpMZjQFdcR4+jpsKJsuW/UL1tG9rOnfGcNAnva8egqikFn0hw\n8gKgNjubqnXr0cXGousRjcrp0n8YmvPzMe7ahVNiohwtdJlkuEvSGRRF4ViRgSx9NUcLqlibVsjW\nEyX1ox27+LkQ7OXMwEgfDDUWjhRU4uKoIdTLCX93HQmhnkQFuKFWCQy1Fvt085xLraFurp3Cg5C9\nE8wGMBvrbvp6hkFlHpQer9turXtaV3EJpDLHGf1+C9XZFrQuFry7G/CMNCI6xVCwywP95oz6oaBC\no8a5ZyRO3YJx7j8ITVR/bDW1aHy80fj6Ihwc+DNLzuznr1y7jpwZM1Bq6p5tcBkyBI+JE3AbPVo+\nDXwJZLhLUiOUVNWwN6ec/dnl7M4qI6PYwPFiA2qVINzHGWOtldxyU/3+WrXAQa3CUGuli58LMZ08\nSOzsSUyQO4lhXpe8WlWLqKmCgv2QvQMK0+pu9FrNVGUpFG8qxpiei8rJAZ2/mupMI56RBtxCTNis\nKoxFWipzdZir1MDp4S00ahzCQrGUV2EzGFB7euIYEYE2JATH7lEUzZqNNigI3wceoGrD7xg2/4El\nPx+Vuztuo0fhNnw4TomJaLy87PO5tDEy3CXpEhVWmHBx1ODiWDdE0WZTOFlazdbjJZwoNmA0W/Fw\n0nI4v5JdJ8sorqq7IvVw0nLrgM5M6h1CV39Xe76Fi6YoCsZdu9B//Q1Vmzbx/+3da3Bc5XnA8f+z\n99WuVvfLCkm2ZIyNsakDDRgwBGgKgTRkMs1MIe0UQtI07WRSpjPp4KbNTPqlNB86bWc6Q5g2035I\nSNIGGheSOpBAk9IUY/AFW8KWZGzrrtVlb9r7nrcfzrEsHIFlW/Jaq+c3c2bPec+7u+9z5ujR2fOe\n8566jz9A25c/j4SbQVx2h3A+RXk+R+YX+yj0H8KdOU05NkIx7aEw70bEhbe1nnzKRzFeppwpYGXz\n4PHQ+/xz+Ddvtr/Lssjs30/8B8+RevllTDYLXi/BG2+k+YtfJHTH7doP8AE0uSt1BRhjmE4XePP0\nLM8fHGXfsUnAfvbsx2+M8uGNjfS2hK+a8/krbn4Gpk/A7BBM9cP4YfvXQXYOY6CUcWMs8HW0QW2b\n3SfQ2AstW6BtOxYBMiNZ0q/+nNQrr1IaH8fT0oKvtxcrmyW4YweumiC+TZvwdXfj7ehY9+fsNbkr\nVQETiRwvHBnj+weGOTGZXijvbAgSCXiZTudprwtwQ0eEbR117LimjmhdgJawf/XGvr/SLAvSE/bR\n/uy7MPeu/Zoad/oHhiCz6EHsLg80bcYiSGLAMD/uopgoQ7lAbjRx7m41R3Dnr1H70Y8S2r0bd0MD\n4nbjjkRW/TGLVi7H9NNPM/fsd3H5fLQ88QS199+POxy68JtXkCZ3pSpsKpnjzdNznJrJcHQsQa5Q\npq7Gy2Qyx9sjCZK50kLd5rCfmzfUs6klzJb2Wm7qbqCzIVi9NyElx2BmEOanYeIIxI7biT+fhOkB\nKNj/GK2SUEi7sYou8gkPhZSH9JifQupXfwnV3PJhQrffgae1FW+0Hd/GjXja21dkG+b6+xn9ylco\nDMEX7JEAAAulSURBVA4Ruv025v/3lwBIMEjdJz5B42cfw9/Tc9nfsxya3JW6ihljGJnLcngkzlQy\nz+GROAfPxBmLZyk5R6rNYT+RoIcan5umkJ+msI+g121PPjc1Pg87rrGP/utqqui0j2VBLm5fklnM\nAGIP6TB70j7inxmk8M5Bsn3HseZimGKB3JyP3KyXfOK928EV9BLobMTb0Yp3w3WU5ktk+07gbW/H\n19ODb0M3NZ0+fMUBBMs+bRTpsO8Kro1CKUfyldcYe+oZ3PV1RP/6KcJ37sYUCmTeeovkiy8S/48f\nQrGI79pNRB54gPCdd+LfuhXXKv2S0OSu1BpUKFkMTKU4eCbOG6dmKVmGbKHMeCJHKlckVyyTLZTJ\nFsvvOVvR2RCktdbPzq4Gfm9XN92NNXiu5it3VlJy3B7qYe5dShOjlGKTlGdnyY/NkDsTJxuDQsoD\nRnB5LVw+EJehmHaBOXdUL24Lb6hMTXMBX6REpCuLuGDoxVb89SU675zF070NNu6G7l3QtBn8tRSm\nEqRefY3US/vIHj2+8Hnezk4C27cT2nUr5WSKXF8fViqFr6eHhs88gr+395LC1eSuVBUzxpDIFjky\nkuDoWIK+sSTjiRxHRuIUy/bfdMjnZms0wkeua6Eh5COZLVK2DF2NQbZF69jUElof/wAsC2usD5l+\nB5KnkOQYeINYRYtiqkx6KIcV7KQ8n6Vw8iSZtw5iCsVz73e56H36L/GbYfu5vcP7oZRd8qtKWRfz\nk36yMz5KpTDZaTellH36zb5ktIPCmQkafudTtP3F1y8pHE3uSq1D44ksL/dNMjtfZC5T4PV3Z+kf\nTy5Z1+dxsbW9lo1NIcqWIV8qky9ZFEoWljEIwqbWELt6m2iPBNjZXY/fU/3j0ZTT8+TePkL+5EkK\np08Tuu02au+551yFUsG+Kig5avcNFDL2jWO1HdB2A6Qn7ZvJYv2YscMUhidw+0q4vQVEoJRzwa1/\niOdTT11S+zS5K6UA+5m2xbJFOODB7RJOz2ToG0vSN57k2FiCkbksXrcLv8eFz+N6z41Y/WNJUnn7\nyDPgdbG9o46O+iDtdQG8buG6tlp6m+1OYJ9nHfwKuBzp2MJlorTvgObNl/QxmtyVUpetVLY4MZnm\n9Mw8/3dyhv7xFBPJHBPJHIWStVBPBFpr/dy8oYG7t7TS2RBkZC5LJl9iLlPk2tYwO7vqmS+UODKc\n4OcDMeYyBcqWoVCyiNYH2RaNsKXNHo8/mStSsgzJbJFoXZDr2sJc2xp+3ytfEpkig7E0HfUB2moD\n1XNZ6RI0uSulVo0xhnzJ4tTMPAOTaQam0ozMZvifwWmmUvkLvr89EiBaH8DjEtwuYXg2y2h86fPY\nZ/U2h9i1qYm7NjfzG9e3LfzCOHhmjsf/5Q3mnAe5tEX8PLA9yid3dvCh7uob0kCTu1LqirMsw4mp\nFJPJPD1NIcIBD0Gvm7dHEwzF0tT43GxureX66K8+SCSeKXB6JkPJMjSFfHiccXwmk3kOjcT5ybEJ\nDg3HSeVKNNR46W0JMxRLE88U6W6s4c8f3MpUKs8vBqb57+MxCmWLbdEI993Qxse2t7OlrToeXqLJ\nXSlVdUpli1eOx/jx0XGGYvNsag7RGPLx+O4eOurPDUmczBV59vUzvNQ3yZtn7KEQuhqD3NrTxD1b\nWjEYonUBuhtDNId9iAjGGCzDks/jtSyDZcxVcXWRJnellAJiqTz/dXSc1wZneG1weqGD+Kyg182G\nphpm5gvEUnnCfg8ttX4aarwUyhbGwJnZDMWyxY5r6tjZVU9jyI/XLVjGsP2aOm7qbiDgvTJXEmly\nV0qp8+RLZfrHU/g9LsbiWYZnM5yZzXJmdp5IwEtXYw3pfImpVJ7xeJbagAeDfZOYW4Rfnpzh1Ezm\nPZ3JAD63i+6mGnvo5+56rmuvpSXsp2wME4kciWyRgNfNtmjksoeVWG5y18euK6XWDb/Hzc6uegCu\nj0Yu6TOMMWSLZYplg2UZDg7Psf/dOU46T/zae3jsA9/fHgnwud09/MFdl3aH6nJpcldKqYsgItT4\nzqXOe7e2ce/WtoXl4dkMw7MZYuk8bpfQHglQG/CSzpc4Oprg0HCc1oh/1dupyV0ppVZQV2MNXY01\nS667eUMDj16hdlS+61cppdSK0+SulFJVSJO7UkpVoWUldxH5mIgcF5FBEXlyifWPiUhMRA450+dX\nvqlKKaWW64IdqiLiBv4R+E1gBHhDRPYaY/rOq/o9Y8yXVqGNSimlLtJyjtxvAQaNMSeNMQXgu8An\nV7dZSimlLsdykvs1wPCi5RGn7Hy/LSJHROTfRaRrRVqnlFLqkqxUh+p/AhuNMTcCLwH/ulQlEfmC\niBwQkQOxWGyFvloppdT5lnMT0yiw+Ei80ylbYIyZWbT4T8A3lvogY8wzwDMATgfs6Ytq7TnNwPQl\nvnet0pjXB415fbicmDcsp9JykvsbwGYR6cFO6g8Dn1lcQUSixphxZ/EhoP9CH2qMaVlOA5ciIgeW\nM3BONdGY1weNeX24EjFfMLkbY0oi8iVgH+AGvmWMOSYifwUcMMbsBb4sIg8BJWAWeGwV26yUUuoC\nljW2jDHmR8CPziv72qL5PcCelW2aUkqpS7VW71B9ptINqACNeX3QmNeHVY+5Yg/rUEoptXrW6pG7\nUkqpD7DmkvuFxrlZS0TkWyIyJSJHF5U1ishLIjLgvDY45SIi/+DEfUREblr0nked+gMicqWGi75o\nItIlIq+ISJ+IHBORP3HKqznmgIjsF5HDTsxfd8p7ROR1J7bviYjPKfc7y4PO+o2LPmuPU35cRO6v\nTETLJyJuETkoIi84y1Uds4icEpG3nfG1Djhlldu3jTFrZsK+WmcI6AV8wGFgW6XbdRnx3AXcBBxd\nVPYN4Eln/kngb5z5B4EfAwLsAl53yhuBk85rgzPfUOnY3ifeKHCTM18LnAC2VXnMAoSdeS/wuhPL\n94GHnfKngT9y5v8YeNqZfxh7zCac7XQY8AM9zt+Bu9LxXSD2PwW+A7zgLFd1zMApoPm8sort2xXf\nIBe58W4D9i1a3gPsqXS7LjOmjecl9+NA1JmPAsed+W8Cj5xfD3gE+Oai8vfUu5on4IfYA9Kti5iB\nGuAt4FbsG1g8TvnCfo19yfFtzrzHqSfn7+uL612NE/bNjj8F7gVecGKo9piXSu4V27fX2mmZ5Y5z\ns5a1mXM3hE0AZx/O+H6xr8lt4vz0/hD2kWxVx+ycnjgETGEPzzEExI0xJafK4vYvxOasTwBNrLGY\ngb8D/gywnOUmqj9mA/xERN4UkS84ZRXbt/UZqlcxY4wRkaq7nElEwsAPgCeMMUkRWVhXjTEbY8rA\nThGpB54Htla4SatKRH4LmDLGvCkid1e6PVfQbmPMqIi0Ai+JyDuLV17pfXutHblfcJybKjApIlGw\nh3XAPtqD9499TW0TEfFiJ/ZvG2Oec4qrOuazjDFx4BXsUxL1InL24Gpx+xdic9bXATOsrZjvAB4S\nkVPYQ4TfC/w91R0zxphR53UK+5/4LVRw315ryX1hnBunp/1hYG+F27TS9sLCA9IfxT4vfbb8951e\n9l1Awvm5tw+4T0QanJ74+5yyq47Yh+j/DPQbY/520apqjrnFOWJHRILYfQz92En+006182M+uy0+\nDfzM2Cdf9wIPO1eW9ACbgf1XJoqLY4zZY4zpNMZsxP4b/Zkx5nep4phFJCQitWfnsffJo1Ry3650\nJ8QldFo8iH2VxRDw1Uq35zJjeRYYB4rY59Y+h32u8afAAPAy0OjUFewnYg0BbwO/vuhzHgcGnemz\nlY7rA+LdjX1e8ghwyJkerPKYbwQOOjEfBb7mlPdiJ6pB4N8Av1MecJYHnfW9iz7rq862OA48UOnY\nlhn/3Zy7WqZqY3ZiO+xMx87mpkru23qHqlJKVaG1dlpGKaXUMmhyV0qpKqTJXSmlqpAmd6WUqkKa\n3JVSqgppcldKqSqkyV0ppaqQJnellKpC/w+nqoWTMQQtXQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fec58424780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "strategies = ['none', 'sequence', 'element', 'argmax_advantage']\n",
    "#strategies = ['sequence', 'none']\n",
    "for strategy in strategies:\n",
    "    plt.plot(range(num_steps), train_losses_av_mean[strategy][:num_steps])\n",
    "    #plt.fill_between(\n",
    "    #    range(num_steps),\n",
    "    #    train_losses_av_mean[strategy] - train_losses_av_std[strategy],\n",
    "    #    train_losses_av_mean[strategy] + train_losses_av_std[strategy],\n",
    "    #    alpha=0.5\n",
    "    #)\n",
    "plt.legend(strategies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# chunk_length = 8, num_steps = 10000:\n",
    "# none: 0.03 +- 0.00\n",
    "# sequence: 0.03 +- 0.00\n",
    "# element: 0.12 +- 0.00\n",
    "\n",
    "# chunk_length = 16, num_steps = 50000:\n",
    "# none: 0.28 +- 0.01\n",
    "# sequence: 0.39 +- 0.10\n",
    "# element: 1.21 +- 0.07\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
